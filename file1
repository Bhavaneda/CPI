import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# MongoDB connection setup
client = MongoClient('mongodb://localhost:27017/')
db = client['stockdata']
collection = db['daily_price']

def fetch_data_from_mongodb(ticker):
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def split_train_test(data, split_date):
    split_date = pd.to_datetime(split_date)
    train = data[data.index <= split_date]
    test = data[data.index > split_date]
    return train, test

def create_exog_vars(data):
    exog_vars = data[['Open', 'High', 'Low', 'Close', 'Volume']]
    exog_vars['Open_lag'] = exog_vars['Open'].shift(1)
    exog_vars['Close_lag'] = exog_vars['Close'].shift(1)
    exog_vars = exog_vars.dropna()
    return exog_vars

def scale_exog_vars(train_exog, test_exog):
    scaler = StandardScaler()
    scaler.fit(train_exog)
    scaled_train_exog = scaler.transform(train_exog)
    scaled_test_exog = scaler.transform(test_exog)
    return scaled_train_exog, scaled_test_exog, scaler

def train_sarima_model(train_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarima_model = SARIMAX(train_data['Adj Close'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarima_fit = sarima_model.fit(disp=False)
    return sarima_fit

def train_sarimax_model(train_data, exog_vars, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarimax_model = SARIMAX(train_data['Adj Close'], exog=exog_vars, order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarimax_fit = sarimax_model.fit(disp=False)
    return sarimax_fit

def train_var_model(train_data, lag_order=8):
    var_model = VAR(train_data)
    var_fit = var_model.fit(lag_order)
    return var_fit

def forecast_sarima_model(model, steps):
    forecast = model.forecast(steps=steps)
    return forecast

def forecast_sarimax_model(model, train_exog, steps):
    forecast = model.get_forecast(steps=steps, exog=train_exog[-steps:])
    forecasted_mean = forecast.predicted_mean
    return forecasted_mean

def forecast_var_model(model, test_data):
    forecast = model.forecast(test_data.values, steps=len(test_data))
    return forecast[:, 4]

def evaluate_rmse(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    return mean_squared_error(actual_filtered, forecast_filtered, squared=False)

def evaluate_mape(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    if len(actual_filtered) == 0:
        return np.nan
    return (np.abs((actual_filtered - forecast_filtered) / actual_filtered).mean()) * 100

def evaluate_accuracy(actual, forecast):
    mape = evaluate_mape(actual, forecast)
    if np.isnan(mape):
        return np.nan
    return 100 - mape

def validate_models(ticker, split_date, sarima_order=(1, 1, 1), sarima_seasonal_order=(1, 1, 1, 7), sarimax_order=(1, 1, 1), sarimax_seasonal_order=(1, 1, 1, 7), var_lag_order=8):
    try:
        df = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(df)
        
        if 'Close' not in ts.columns:
            raise ValueError(f"Column 'Close' not found in data for {ticker}. Available columns: {ts.columns}")
        
        train_data, test_data = split_train_test(ts, split_date)
        
        # Train and forecast SARIMA model
        sarima_model = train_sarima_model(train_data, sarima_order, sarima_seasonal_order)
        sarima_forecast = forecast_sarima_model(sarima_model, steps=len(test_data))
        
        # Create exogenous variables from training data
        train_exog = create_exog_vars(train_data)
        test_exog = create_exog_vars(test_data)
        
        # Scale the exogenous variables
        scaled_train_exog, scaled_test_exog, scaler = scale_exog_vars(train_exog, test_exog)
        
        # Train and forecast SARIMAX model using scaled exogenous variables
        sarimax_model = train_sarimax_model(train_data.loc[train_exog.index], scaled_train_exog, sarimax_order, sarimax_seasonal_order)
        sarimax_forecast = forecast_sarimax_model(sarimax_model, scaled_train_exog, steps=len(test_data))
        
        # Train and forecast VAR model
        var_model = train_var_model(train_data, var_lag_order)
        var_forecast = forecast_var_model(var_model, test_data)

        # Align forecasts with test data index
        sarima_forecast.index = test_data.index
        sarimax_forecast.index = test_data.index
        var_forecast = pd.Series(var_forecast, index=test_data.index)

        # Print actual and predicted values for the test set
        print(f"Actual and Predicted Values for {ticker}:")
        print("Date\t\tActual\t\tSARIMA\t\tSARIMAX\t\tVAR")
        for idx in range(len(test_data)):
            date = test_data.index[idx]
            actual_value = test_data.iloc[idx]['Adj Close']
            sarima_pred = sarima_forecast[idx]
            sarimax_pred = sarimax_forecast.iloc[idx] if idx < len(sarimax_forecast) else np.nan
            var_pred = var_forecast.iloc[idx]
            print(f"{date}\t{actual_value:.2f}\t{sarima_pred:.2f}\t{sarimax_pred:.2f}\t{var_pred:.2f}")
        
        print()
        # Check indices order
        print("Training set:")
        print(train_data.index.min(), train_data.index.max())
        print("Test set:")
        print(test_data.index.min(), test_data.index.max())

        # Plotting the actual and forecasted values
        plt.figure(figsize=(12, 6))
        plt.plot(test_data.index, test_data['Adj Close'], label='Actual')
        plt.plot(test_data.index, sarima_forecast, label='SARIMA Forecast')
        plt.plot(test_data.index, sarimax_forecast, label='SARIMAX Forecast')
        plt.plot(test_data.index, var_forecast, label='VAR Forecast')
        plt.title(f"{ticker} - Actual vs Forecasted Prices")
        plt.xlabel('Date')
        plt.ylabel('Adj Close Price')
        plt.legend()
        plt.grid(True)
        plt.show()

        # Evaluate models
        sarima_rmse = evaluate_rmse(test_data['Adj Close'], sarima_forecast)
        sarima_mape = evaluate_mape(test_data['Adj Close'], sarima_forecast)
        sarima_accuracy = evaluate_accuracy(test_data['Adj Close'], sarima_forecast)
        
        sarimax_rmse = evaluate_rmse(test_data['Adj Close'], sarimax_forecast)
        sarimax_mape = evaluate_mape(test_data['Adj Close'], sarimax_forecast)
        sarimax_accuracy = evaluate_accuracy(test_data['Adj Close'], sarimax_forecast)
        
        var_rmse = evaluate_rmse(test_data['Adj Close'], var_forecast)
        var_mape = evaluate_mape(test_data['Adj Close'], var_forecast)
        var_accuracy = evaluate_accuracy(test_data['Adj Close'], var_forecast)
        
        results = {
            'SARIMA': {
                'RMSE': sarima_rmse,
                'MAPE': sarima_mape,
                'Accuracy': sarima_accuracy
            },
            'SARIMAX': {
                'RMSE': sarimax_rmse,
                'MAPE': sarimax_mape,
                'Accuracy': sarimax_accuracy
            },
            'VAR': {
                'RMSE': var_rmse,
                'MAPE': var_mape,
                'Accuracy': var_accuracy
            }
        }

        print(f"Model Evaluation for {ticker}:")
        print(f"SARIMA RMSE: {sarima_rmse:.4f}, MAPE: {sarima_mape:.4f}%, Accuracy: {sarima_accuracy:.2f}%")
        print(f"SARIMAX RMSE: {sarimax_rmse:.4f}, MAPE: {sarimax_mape:.4f}%, Accuracy: {sarimax_accuracy:.2f}%")
        print(f"VAR RMSE: {var_rmse:.4f}, MAPE: {var_mape:.4f}%, Accuracy: {var_accuracy:.2f}%")
        
        return results

    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Example usage:
ticker = 'AAPL'
split_date = '2024-06-01'
results = validate_models(ticker, split_date)











import itertools
import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# MongoDB connection setup
client = MongoClient('mongodb://localhost:27017/')
db = client['stockdata']
collection = db['daily_price']

def fetch_data_from_mongodb(ticker):
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']] = np.log1p(df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']])
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def split_train_test(data, split_date):
    split_date = pd.to_datetime(split_date)
    train = data[data.index <= split_date]
    test = data[data.index > split_date]
    return train, test

def create_exog_vars(data):
    exog_vars = data[['Open', 'High', 'Low', 'Close', 'Volume']]
    exog_vars['Open_lag'] = exog_vars['Open'].shift(1)
    exog_vars['Close_lag'] = exog_vars['Close'].shift(1)
    exog_vars['Volume_lag'] = exog_vars['Volume'].shift(1)
    exog_vars['Rolling_Mean_5'] = exog_vars['Close'].rolling(window=5).mean()
    exog_vars['Rolling_Std_5'] = exog_vars['Close'].rolling(window=5).std()
    exog_vars['Rolling_Mean_10'] = exog_vars['Close'].rolling(window=10).mean()
    exog_vars['Rolling_Std_10'] = exog_vars['Close'].rolling(window=10).std()
    exog_vars = exog_vars.dropna()
    return exog_vars

def tune_sarima_model(train_data):
    p = d = q = range(0, 3)
    pdq = list(itertools.product(p, d, q))
    seasonal_pdq = [(x[0], x[1], x[2], 7) for x in pdq]
    
    best_aic = float('inf')
    best_order = None
    best_seasonal_order = None
    
    for param in pdq:
        for param_seasonal in seasonal_pdq:
            try:
                mod = SARIMAX(train_data['Adj Close'], 
                              order=param, 
                              seasonal_order=param_seasonal,
                              enforce_stationarity=False,
                              enforce_invertibility=False)
                results = mod.fit(disp=False)
                
                if results.aic < best_aic:
                    best_aic = results.aic
                    best_order = param
                    best_seasonal_order = param_seasonal
            except:
                continue
                
    return best_order, best_seasonal_order

def tune_sarimax_model(train_data, exog_vars):
    p = d = q = range(0, 3)
    pdq = list(itertools.product(p, d, q))
    seasonal_pdq = [(x[0], x[1], x[2], 7) for x in pdq]
    
    best_aic = float('inf')
    best_order = None
    best_seasonal_order = None
    
    for param in pdq:
        for param_seasonal in seasonal_pdq:
            try:
                mod = SARIMAX(train_data['Adj Close'], 
                              exog=exog_vars,
                              order=param, 
                              seasonal_order=param_seasonal,
                              enforce_stationarity=False,
                              enforce_invertibility=False)
                results = mod.fit(disp=False)
                
                if results.aic < best_aic:
                    best_aic = results.aic
                    best_order = param
                    best_seasonal_order = param_seasonal
            except:
                continue
                
    return best_order, best_seasonal_order

def train_sarima_model(train_data, order, seasonal_order):
    model = SARIMAX(train_data['Adj Close'], 
                    order=order, 
                    seasonal_order=seasonal_order,
                    enforce_stationarity=False,
                    enforce_invertibility=False)
    results = model.fit(disp=False)
    return results

def train_sarimax_model(train_data, exog_vars, order, seasonal_order):
    model = SARIMAX(train_data['Adj Close'], 
                    exog=exog_vars,
                    order=order, 
                    seasonal_order=seasonal_order,
                    enforce_stationarity=False,
                    enforce_invertibility=False)
    results = model.fit(disp=False)
    return results

def forecast_sarima_model(model, steps):
    forecast = model.get_forecast(steps=steps)
    forecast_index = pd.date_range(start=model.data.dates[-1], periods=steps + 1, freq='B')[1:]
    forecast_df = pd.DataFrame({'Forecast': forecast.predicted_mean}, index=forecast_index)
    return forecast_df

def forecast_sarimax_model(model, exog_vars, steps):
    forecast = model.get_forecast(steps=steps, exog=exog_vars.iloc[-steps:])
    forecast_index = pd.date_range(start=model.data.dates[-1], periods=steps + 1, freq='B')[1:]
    forecast_df = pd.DataFrame({'Forecast': forecast.predicted_mean}, index=forecast_index)
    return forecast_df

def train_var_model(train_data):
    model = VAR(train_data)
    results = model.fit(ic='aic')
    return results

def forecast_var_model(model, steps):
    forecast = model.forecast(model.endog, steps=steps)
    forecast_index = pd.date_range(start=model.data.dates[-1], periods=steps + 1, freq='B')[1:]
    forecast_df = pd.DataFrame(forecast, index=forecast_index, columns=model.endog_names)
    return forecast_df[['Adj Close']]

def main():
    ticker = 'AAPL'  # Example ticker
    data = fetch_data_from_mongodb(ticker)
    data = preprocess_data(data)
    
    train_data, test_data = split_train_test(data, '2024-06-03')

    exog_vars = create_exog_vars(train_data)
    test_exog_vars = create_exog_vars(test_data)
    
    # SARIMA Model
    sarima_order, sarima_seasonal_order = tune_sarima_model(train_data)
    sarima_model = train_sarima_model(train_data, sarima_order, sarima_seasonal_order)
    sarima_forecast = forecast_sarima_model(sarima_model, len(test_data))
    
    # SARIMAX Model
    sarimax_order, sarimax_seasonal_order = tune_sarimax_model(train_data, exog_vars)
    sarimax_model = train_sarimax_model(train_data, exog_vars, sarimax_order, sarimax_seasonal_order)
    sarimax_forecast = forecast_sarimax_model(sarimax_model, test_exog_vars, len(test_data))
    
    # VAR Model
    var_model = train_var_model(train_data)
    var_forecast = forecast_var_model(var_model, len(test_data))
    
    # Reverting log transformation
    test_data = np.expm1(test_data['Adj Close'])
    sarima_forecast = np.expm1(sarima_forecast['Forecast'])
    sarimax_forecast = np.expm1(sarimax_forecast['Forecast'])
    var_forecast = np.expm1(var_forecast['Adj Close'])
    
    # Plotting results
    plt.figure(figsize=(12, 6))
    plt.plot(test_data, label='Actual Adj Close')
    plt.plot(sarima_forecast, label='SARIMA Forecast')
    plt.plot(sarimax_forecast, label='SARIMAX Forecast')
    plt.plot(var_forecast, label='VAR Forecast')
    plt.legend()
    plt.title(f'{ticker} Stock Price Forecast')
    plt.show()

if __name__ == "__main__":
    main()














import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# MongoDB connection setup
client = MongoClient('mongodb://localhost:27017/')
db = client['stockdata']
collection = db['daily_price']

def fetch_data_from_mongodb(ticker):
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def split_train_test(data, split_date):
    split_date = pd.to_datetime(split_date)
    train = data[data.index <= split_date]
    test = data[data.index > split_date]
    return train, test

def create_exog_vars(data):
    exog_vars = data[['Open', 'High', 'Low', 'Close', 'Volume']]
    exog_vars['Open_lag'] = exog_vars['Open'].shift(1)
    exog_vars['Close_lag'] = exog_vars['Close'].shift(1)
    exog_vars = exog_vars.dropna()
    return exog_vars

def train_sarima_model(train_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarima_model = SARIMAX(train_data['Adj Close'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarima_fit = sarima_model.fit(disp=False)
    return sarima_fit

def train_sarimax_model(train_data, exog_vars, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarimax_model = SARIMAX(train_data['Adj Close'], exog=exog_vars, order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarimax_fit = sarimax_model.fit(disp=False)
    return sarimax_fit

def train_var_model(train_data, lag_order=8):
    var_model = VAR(train_data)
    var_fit = var_model.fit(lag_order)
    return var_fit

def forecast_sarima_model(model, steps):
    forecast = model.forecast(steps=steps)
    return forecast

def forecast_sarimax_model(model, train_exog, steps):
    forecast = model.get_forecast(steps=steps, exog=train_exog.iloc[-steps:])
    forecasted_mean = forecast.predicted_mean
    return forecasted_mean

def forecast_var_model(model, test_data):
    forecast = model.forecast(test_data.values, steps=len(test_data))
    return forecast[:, 4]

def evaluate_rmse(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    return mean_squared_error(actual_filtered, forecast_filtered, squared=False)

def evaluate_mape(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    if len(actual_filtered) == 0:
        return np.nan
    return (np.abs((actual_filtered - forecast_filtered) / actual_filtered).mean()) * 100

def evaluate_accuracy(actual, forecast):
    mape = evaluate_mape(actual, forecast)
    if np.isnan(mape):
        return np.nan
    return 100 - mape

def validate_models(ticker, split_date, sarima_order=(1, 1, 1), sarima_seasonal_order=(1, 1, 1, 7), sarimax_order=(1, 1, 1), sarimax_seasonal_order=(1, 1, 1, 7), var_lag_order=8):
    try:
        df = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(df)
        
        if 'Close' not in ts.columns:
            raise ValueError(f"Column 'Close' not found in data for {ticker}. Available columns: {ts.columns}")
        
        train_data, test_data = split_train_test(ts, split_date)
        
        # Train and forecast SARIMA model
        sarima_model = train_sarima_model(train_data, sarima_order, sarima_seasonal_order)
        sarima_forecast = forecast_sarima_model(sarima_model, steps=len(test_data))
        
        # Create exogenous variables from training data
        train_exog = create_exog_vars(train_data)
        
        # Train and forecast SARIMAX model using training data exog
        sarimax_model = train_sarimax_model(train_data.loc[train_exog.index], train_exog, sarimax_order, sarimax_seasonal_order)
        sarimax_forecast = forecast_sarimax_model(sarimax_model, train_exog, steps=len(test_data))
        
        # Train and forecast VAR model
        var_model = train_var_model(train_data, var_lag_order)
        var_forecast = forecast_var_model(var_model, test_data)

        # Align forecasts with test data index
        sarima_forecast.index = test_data.index
        sarimax_forecast.index = test_data.index
        var_forecast = pd.Series(var_forecast, index=test_data.index)

        # Print actual and predicted values for the test set
        print(f"Actual and Predicted Values for {ticker}:")
        print("Date\t\tActual\t\tSARIMA\t\tSARIMAX\t\tVAR")
        for idx in range(len(test_data)):
            date = test_data.index[idx]
            actual_value = test_data.iloc[idx]['Adj Close']
            sarima_pred = sarima_forecast[idx]
            sarimax_pred = sarimax_forecast.iloc[idx] if idx < len(sarimax_forecast) else np.nan
            var_pred = var_forecast.iloc[idx]
            print(f"{date}\t{actual_value:.2f}\t{sarima_pred:.2f}\t{sarimax_pred:.2f}\t{var_pred:.2f}")
        
        print()
        # Check indices order
        print("Training set:")
        print(train_data.index.min(), train_data.index.max())
        print("Test set:")
        print(test_data.index.min(), test_data.index.max())

        # Plotting the actual and forecasted values
        plt.figure(figsize=(12, 6))
        plt.plot(test_data.index, test_data['Adj Close'], label='Actual')
        plt.plot(test_data.index, sarima_forecast, label='SARIMA Forecast')
        plt.plot(test_data.index, sarimax_forecast, label='SARIMAX Forecast')
        plt.plot(test_data.index, var_forecast, label='VAR Forecast')
        plt.title(f"{ticker} - Actual vs Forecasted Prices")
        plt.xlabel('Date')
        plt.ylabel('Adj Close Price')
        plt.legend()
        plt.grid(True)
        plt.show()

        # Evaluate models
        sarima_rmse = evaluate_rmse(test_data['Adj Close'], sarima_forecast)
        sarima_mape = evaluate_mape(test_data['Adj Close'], sarima_forecast)
        sarima_accuracy = evaluate_accuracy(test_data['Adj Close'], sarima_forecast)
        
        sarimax_rmse = evaluate_rmse(test_data['Adj Close'], sarimax_forecast)
        sarimax_mape = evaluate_mape(test_data['Adj Close'], sarimax_forecast)
        sarimax_accuracy = evaluate_accuracy(test_data['Adj Close'], sarimax_forecast)
        
        var_rmse = evaluate_rmse(test_data['Adj Close'], var_forecast)
        var_mape = evaluate_mape(test_data['Adj Close'], var_forecast)
        var_accuracy = evaluate_accuracy(test_data['Adj Close'], var_forecast)

        print(f"Validation results for {ticker}:")
        print(f"SARIMA RMSE: {sarima_rmse}")
        print(f"SARIMA MAPE: {sarima_mape}")
        print(f"SARIMA Accuracy: {sarima_accuracy}%")
        print(f"SARIMAX RMSE: {sarimax_rmse}")
        print(f"SARIMAX MAPE: {sarimax_mape}")
        print(f"SARIMAX Accuracy: {sarimax_accuracy}%")
        print(f"VAR RMSE: {var_rmse}")
        print(f"VAR MAPE: {var_mape}")
        print(f"VAR Accuracy: {var_accuracy}%")

    except ValueError as e:
        print(f"ValueError: {str(e)}")
    except Exception as e:
        print(f"An error occurred: {str(e)}")

ticker = 'AAPL'
split_date = '2024-06-03'
validate_models(ticker, split_date)









import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# MongoDB connection setup
client = MongoClient('mongodb://localhost:27017/')
db = client['stockdata']
collection = db['daily_price']

def fetch_data_from_mongodb(ticker):
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def split_train_test(data, split_date):
    split_date = pd.to_datetime(split_date)
    train = data[data.index <= split_date]
    test = data[data.index > split_date]
    return train, test

def train_sarima_model(train_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarima_model = SARIMAX(train_data['Adj Close'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarima_fit = sarima_model.fit(disp=False)
    return sarima_fit

def train_sarimax_model(train_data, exog_vars, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarimax_model = SARIMAX(train_data['Adj Close'], exog=exog_vars, order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarimax_fit = sarimax_model.fit(disp=False)
    return sarimax_fit

def train_var_model(train_data, lag_order=8):
    var_model = VAR(train_data)
    var_fit = var_model.fit(lag_order)
    return var_fit

def forecast_sarima_model(model, test_data):
    forecast = model.forecast(steps=len(test_data))
    return forecast

def forecast_sarimax_model(model, test_data, train_data):
    # Prepare exogenous variables for forecasting
    test_exog = test_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']]
    
    # Prepare lagged exogenous variables from training data
    train_exog = train_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']]
    train_exog['Open_lag'] = train_exog['Open'].shift(1)
    train_exog['Close_lag'] = train_exog['Close'].shift(1)
    train_exog.dropna(inplace=True)
    
    # Forecast using SARIMAX model with lagged exogenous variables
    forecast = model.get_forecast(steps=len(test_data), exog=train_exog[-len(test_data):])
    
    # Extract predicted mean
    forecasted_mean = forecast.predicted_mean
    
    return forecasted_mean

def forecast_var_model(model, test_data):
    forecast = model.forecast(test_data.values, steps=len(test_data))
    return forecast[:, 4]

def evaluate_rmse(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    return mean_squared_error(actual_filtered, forecast_filtered, squared=False)

def evaluate_mape(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    if len(actual_filtered) == 0:
        return np.nan
    return (np.abs((actual_filtered - forecast_filtered) / actual_filtered).mean()) * 100

def evaluate_accuracy(actual, forecast):
    mape = evaluate_mape(actual, forecast)
    if np.isnan(mape):
        return np.nan
    return 100 - mape

def validate_models(ticker, split_date, sarima_order=(1, 1, 1), sarima_seasonal_order=(1, 1, 1, 7), sarimax_order=(1, 1, 1), sarimax_seasonal_order=(1, 1, 1, 7), var_lag_order=8):
    try:
        df = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(df)
        
        if 'Close' not in ts.columns:
            raise ValueError(f"Column 'Close' not found in data for {ticker}. Available columns: {ts.columns}")
        
        train_data, test_data = split_train_test(ts, split_date)
        
        # Train and forecast SARIMA model
        sarima_model = train_sarima_model(train_data, sarima_order, sarima_seasonal_order)
        sarima_forecast = forecast_sarima_model(sarima_model, test_data)
        
        # Train and forecast SARIMAX model
        exog_vars = train_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']]
        sarimax_model = train_sarimax_model(train_data, exog_vars, sarimax_order, sarimax_seasonal_order)
        sarimax_forecast = forecast_sarimax_model(sarimax_model, test_data, train_data)
        
        # Train and forecast VAR model
        var_model = train_var_model(train_data, var_lag_order)
        var_forecast = forecast_var_model(var_model, test_data)

        # Align forecasts with test data index
        sarima_forecast.index = test_data.index
        sarimax_forecast.index = test_data.index
        var_forecast = pd.Series(var_forecast, index=test_data.index)

        # Print actual and predicted values for the test set
        print(f"Actual and Predicted Values for {ticker}:")
        print("Date\t\tActual\t\tSARIMA\t\tSARIMAX\t\tVAR")
        for idx in range(len(test_data)):
            date = test_data.index[idx]
            actual_value = test_data.iloc[idx]['Adj Close']
            sarima_pred = sarima_forecast.iloc[idx]
            sarimax_pred = sarimax_forecast.iloc[idx]
            var_pred = var_forecast.iloc[idx]
            print(f"{date}\t{actual_value:.2f}\t{sarima_pred:.2f}\t{sarimax_pred:.2f}\t{var_pred:.2f}")
        
        print()
        # Check indices order
        print("Training set:")
        print(train_data.index.min(), train_data.index.max())
        print("Test set:")
        print(test_data.index.min(), test_data.index.max())

        # Plotting the actual and forecasted values
        plt.figure(figsize=(12, 6))
        plt.plot(test_data.index, test_data['Adj Close'], label='Actual')
        plt.plot(test_data.index, sarima_forecast, label='SARIMA Forecast')
        plt.plot(test_data.index, sarimax_forecast, label='SARIMAX Forecast')
        plt.plot(test_data.index, var_forecast, label='VAR Forecast')
        plt.title(f"{ticker} - Actual vs Forecasted Prices")
        plt.xlabel('Date')
        plt.ylabel('Adj Close Price')
        plt.legend()
        plt.grid(True)
        plt.show()

        # Evaluate models
        sarima_rmse = evaluate_rmse(test_data['Adj Close'], sarima_forecast)
        sarima_mape = evaluate_mape(test_data['Adj Close'], sarima_forecast)
        sarima_accuracy = evaluate_accuracy(test_data['Adj Close'], sarima_forecast)
        
        sarimax_rmse = evaluate_rmse(test_data['Adj Close'], sarimax_forecast)
        sarimax_mape = evaluate_mape(test_data['Adj Close'], sarimax_forecast)
        sarimax_accuracy = evaluate_accuracy(test_data['Adj Close'], sarimax_forecast)
        
        var_rmse = evaluate_rmse(test_data['Adj Close'], var_forecast)
        var_mape = evaluate_mape(test_data['Adj Close'], var_forecast)
        var_accuracy = evaluate_accuracy(test_data['Adj Close'], var_forecast)

        print(f"Validation results for {ticker}:")
        print(f"SARIMA RMSE: {sarima_rmse}")
        print(f"SARIMA MAPE: {sarima_mape}")
        print(f"SARIMA Accuracy: {sarima_accuracy}%")
        print(f"SARIMAX RMSE: {sarimax_rmse}")
        print(f"SARIMAX MAPE: {sarimax_mape}")
        print(f"SARIMAX Accuracy: {sarimax_accuracy}%")
        print(f"VAR RMSE: {var_rmse}")
        print(f"VAR MAPE: {var_mape}")
        print(f"VAR Accuracy: {var_accuracy}%")
        
        return sarima_rmse, sarimax_rmse, var_rmse, sarima_accuracy, sarimax_accuracy, var_accuracy
    
    except Exception as e:
        print(f"Error validating models for {ticker}: {str(e)}")
        return None, None, None, None, None, None

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    split_date = datetime(2024, 6, 1)
    
    for ticker in tickers:
        print(f"Validating models for {ticker}...")
        validate_models(ticker, split_date)
        print()
    
    # Close MongoDB client connection at the end
    client.close()















import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# MongoDB connection setup
client = MongoClient('mongodb://localhost:27017/')
db = client['stockdata']
collection = db['daily_price']

def fetch_data_from_mongodb(ticker):
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def split_train_test(data, split_date):
    split_date = pd.to_datetime(split_date)
    train = data[data.index <= split_date]
    test = data[data.index > split_date]
    return train, test

def train_sarima_model(train_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarima_model = SARIMAX(train_data['Adj Close'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarima_fit = sarima_model.fit(disp=False)
    return sarima_fit

def train_sarimax_model(train_data, exog_vars, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    sarimax_model = SARIMAX(train_data['Adj Close'], exog=exog_vars, order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
    sarimax_fit = sarimax_model.fit(disp=False)
    return sarimax_fit

def train_var_model(train_data, lag_order=8):
    var_model = VAR(train_data)
    var_fit = var_model.fit(lag_order)
    return var_fit

def forecast_sarima_model(model, test_data):
    forecast = model.forecast(steps=len(test_data))
    return forecast

def forecast_sarimax_model(model, test_data, exog_vars):
    forecast = model.get_forecast(steps=len(test_data), exog=exog_vars)
    return forecast.predicted_mean

def forecast_var_model(model, test_data):
    forecast = model.forecast(test_data.values, steps=len(test_data))
    return forecast[:, 4]

def evaluate_rmse(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    return mean_squared_error(actual_filtered, forecast_filtered, squared=False)

def evaluate_mape(actual, forecast):
    mask = ~np.isnan(actual) & (actual != 0)
    actual_filtered = actual[mask]
    forecast_filtered = forecast[mask]
    if len(actual_filtered) == 0:
        return np.nan
    return (np.abs((actual_filtered - forecast_filtered) / actual_filtered).mean()) * 100

def evaluate_accuracy(actual, forecast):
    mape = evaluate_mape(actual, forecast)
    if np.isnan(mape):
        return np.nan
    return 100 - mape

def validate_models(ticker, split_date, sarima_order=(1, 1, 1), sarima_seasonal_order=(1, 1, 1, 7), sarimax_order=(1, 1, 1), sarimax_seasonal_order=(1, 1, 1, 7), var_lag_order=8):
    try:
        df = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(df)
        train_data, test_data = split_train_test(ts, split_date)
        
        # Train and forecast SARIMA model
        sarima_model = train_sarima_model(train_data, sarima_order, sarima_seasonal_order)
        sarima_forecast = forecast_sarima_model(sarima_model, test_data)
        
        # Train and forecast SARIMAX model
        exog_vars = train_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']]
        sarimax_model = train_sarimax_model(train_data, exog_vars, sarimax_order, sarimax_seasonal_order)
        sarimax_forecast = forecast_sarimax_model(sarimax_model, test_data, test_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']])
        
        # Train and forecast VAR model
        var_model = train_var_model(train_data, var_lag_order)
        var_forecast = forecast_var_model(var_model, test_data)

        # Align forecasts with test data index
        sarima_forecast.index = test_data.index
        sarimax_forecast.index = test_data.index
        var_forecast = pd.Series(var_forecast, index=test_data.index)

        # Print actual and predicted values for the test set
        print(f"Actual and Predicted Values for {ticker}:")
        print("Date\t\tActual\t\tSARIMA\t\tSARIMAX\t\tVAR")
        for idx in range(len(test_data)):
            date = test_data.index[idx]
            actual_value = test_data.iloc[idx]['Adj Close']
            sarima_pred = sarima_forecast.iloc[idx]
            sarimax_pred = sarimax_forecast.iloc[idx]
            var_pred = var_forecast.iloc[idx]
            print(f"{date}\t{actual_value:.2f}\t{sarima_pred:.2f}\t{sarimax_pred:.2f}\t{var_pred:.2f}")
        
        print()
        # Check indices order
        print("Training set:")
        print(train_data.index.min(), train_data.index.max())
        print("Test set:")
        print(test_data.index.min(), test_data.index.max())

        # Plotting the actual and forecasted values
        plt.figure(figsize=(12, 6))
        plt.plot(test_data.index, test_data['Adj Close'], label='Actual')
        plt.plot(test_data.index, sarima_forecast, label='SARIMA Forecast')
        plt.plot(test_data.index, sarimax_forecast, label='SARIMAX Forecast')
        plt.plot(test_data.index, var_forecast, label='VAR Forecast')
        plt.title(f"{ticker} - Actual vs Forecasted Prices")
        plt.xlabel('Date')
        plt.ylabel('Adj Close Price')
        plt.legend()
        plt.grid(True)
        plt.show()

        # Evaluate models
        sarima_rmse = evaluate_rmse(test_data['Adj Close'], sarima_forecast)
        sarima_mape = evaluate_mape(test_data['Adj Close'], sarima_forecast)
        sarima_accuracy = evaluate_accuracy(test_data['Adj Close'], sarima_forecast)
        
        sarimax_rmse = evaluate_rmse(test_data['Adj Close'], sarimax_forecast)
        sarimax_mape = evaluate_mape(test_data['Adj Close'], sarimax_forecast)
        sarimax_accuracy = evaluate_accuracy(test_data['Adj Close'], sarimax_forecast)
        
        var_rmse = evaluate_rmse(test_data['Adj Close'], var_forecast)
        var_mape = evaluate_mape(test_data['Adj Close'], var_forecast)
        var_accuracy = evaluate_accuracy(test_data['Adj Close'], var_forecast)

        print(f"Validation results for {ticker}:")
        print(f"SARIMA RMSE: {sarima_rmse}")
        print(f"SARIMA MAPE: {sarima_mape}")
        print(f"SARIMA Accuracy: {sarima_accuracy}%")
        print(f"SARIMAX RMSE: {sarimax_rmse}")
        print(f"SARIMAX MAPE: {sarimax_mape}")
        print(f"SARIMAX Accuracy: {sarimax_accuracy}%")
        print(f"VAR RMSE: {var_rmse}")
        print(f"VAR MAPE: {var_mape}")
        print(f"VAR Accuracy: {var_accuracy}%")
        
        return sarima_rmse, sarimax_rmse, var_rmse, sarima_accuracy, sarimax_accuracy, var_accuracy
    
    except Exception as e:
        print(f"Error validating models for {ticker}: {str(e)}")
        return None, None, None, None, None, None

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    split_date = datetime(2024, 6, 1)
    
    for ticker in tickers:
        print(f"Validating models for {ticker}...")
        validate_models(ticker, split_date)
        print()
    
    # Close MongoDB client connection at the end
    client.close()












VAR MODEL
train.py
import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.vector_ar.var_model import VAR
import pickle
import os
import warnings
warnings.filterwarnings("ignore")

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def train_model(ticker, df, lag_order=8):
    try:
        model = VAR(df)
        fitted_model = model.fit(lag_order)
        os.makedirs('models', exist_ok=True)
        with open(f'models/{ticker}_var_model.pkl', 'wb') as f:
            pickle.dump(fitted_model, f)
        print(f"VAR model trained and saved successfully for {ticker}.")
    except Exception as e:
        print(f"Error training VAR model for {ticker}: {str(e)}")

if _name_ == '_main_':
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN','META','F','CAT','TCS.NS','WFC','TATASTEEL.NS','NFLX','RS','JPM','TSLA']
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_model(ticker, ts, 8)

app.py
from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.vector_ar.var_model import VAR
import warnings

app = Flask(_name_)

# Suppress warnings
warnings.filterwarnings("ignore")

# Function to load VAR models from pickle files
def load_var_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    models = {}
    for ticker in tickers:
        try:
            with open(f'models/{ticker}_var_model.pkl', 'rb') as f:
                model = pickle.load(f)
                models[ticker] = model
                print(f"Loaded VAR model for {ticker}.")
        except Exception as e:
            print(f"Error loading VAR model for {ticker}: {str(e)}")
    return models

# Function to fetch historical data from MongoDB
def fetch_historical_data(ticker):
    try:
        client = MongoClient('mongodb://localhost:27017/')
        db = client['stockdata']
        collection = db['daily_price']
        cursor = collection.find({'Ticker': ticker})
        df = pd.DataFrame(list(cursor))
        client.close()
        return df
    except Exception as e:
        print(f"Error fetching data from MongoDB for {ticker}: {str(e)}")
        return None

# Function to preprocess data for VAR model prediction
def preprocess_data_for_var(df):
    try:
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]
    except Exception as e:
        print(f"Error preprocessing data for VAR model: {str(e)}")
        return None

# Function to predict stock prices using a VAR model
def predict_stock_prices(var_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_var(latest_data)
        if ts is None:
            print("Preprocessed data is None.")
            return None
        
        lag_order = var_model.k_ar
        forecast_input = ts.values[-lag_order:]
        
        if len(forecast_input) < lag_order:
            print("Not enough data to make predictions.")
            return None

        # Number of days to predict to reach the current date and 30 days ahead
        last_date = ts.index[-1]
        current_date = datetime.now().date()
        days_to_current_date = (current_date - last_date.date()).days
        total_days_ahead = days_to_current_date + days_ahead

        forecast_index = pd.date_range(start=ts.index[-1], periods=total_days_ahead + 1, freq='D')[1:]
        
        forecast = var_model.forecast(forecast_input, steps=len(forecast_index))
        predicted_closes = forecast[:, 4]

        target_dates = [forecast_index[i].strftime('%Y-%m-%d') for i in range(len(forecast_index))]
        predictions = {target_dates[i]: predicted_closes[i] for i in range(len(forecast_index))}

        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices using VAR model: {str(e)}")
        return None

# Load VAR models on application startup
models = load_var_models()

@app.route('/predict/next_month', methods=['POST'])
def predict_next_month():
    ticker = request.json['ticker']
    
    try:
        if ticker not in models:
            return jsonify({'error': f'Model for {ticker} not found.'}), 404
        
        historical_data = fetch_historical_data(ticker)
        if historical_data is None:
            return jsonify({'error': f'Failed to fetch historical data for {ticker}.'}), 500
        
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            current_date = datetime.now().date().strftime('%Y-%m-%d')
            predictions = {date: value for date, value in predictions.items() if date >= current_date}
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if _name_ == '_main_':
    app.run(debug=True)


SARIMA MODEL
train.py
import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
import pickle
import os
import warnings
# Suppress warnings
warnings.filterwarnings("ignore")

def fetch_data_from_mongodb(ticker):
    
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data(df):
   
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def train_sarima_model(ticker, df, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    
    try:
        model = SARIMAX(df['Adj Close'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
        fitted_model = model.fit(disp=False)
        os.makedirs('models', exist_ok=True)
        with open(f'models/{ticker}_sarima_model.pkl', 'wb') as f:
            pickle.dump(fitted_model, f)
        print(f"SARIMA model trained and saved successfully for {ticker}.")
    except Exception as e:
        print(f"Error training SARIMA model for {ticker}: {str(e)}")

if _name_ == '_main_':
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_sarima_model(ticker, ts)

app.py
from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.statespace.sarimax import SARIMAX

app = Flask(_name_)

# Function to load SARIMA models from pickle files
def load_sarima_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    models = {}
    for ticker in tickers:
        try:
            with open(f'models/{ticker}_sarima_model.pkl', 'rb') as f:
                model = pickle.load(f)
                models[ticker] = model
                print(f"Loaded SARIMA model for {ticker}.")
        except Exception as e:
            print(f"Error loading SARIMA model for {ticker}: {str(e)}")
    return models

# Function to fetch historical data from MongoDB
def fetch_historical_data(ticker):
    try:
        client = MongoClient('mongodb://localhost:27017/')
        db = client['stockdata']
        collection = db['daily_price']
        cursor = collection.find({'Ticker': ticker})
        df = pd.DataFrame(list(cursor))
        client.close()
        return df
    except Exception as e:
        print(f"Error fetching data from MongoDB for {ticker}: {str(e)}")
        return None

# Function to preprocess data for SARIMA model prediction
def preprocess_data_for_sarima(df):
    try:
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        return df[['Adj Close']]  # Using 'Adj Close' price for SARIMA
    except Exception as e:
        print(f"Error preprocessing data for SARIMA model: {str(e)}")
        return None

# Function to predict stock prices using a SARIMA model
def predict_stock_prices_sarima(sarima_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_sarima(latest_data)
        if ts is None:
            return None

        # Number of days to predict to reach the current date and 30 days ahead
        last_date = ts.index[-1]
        current_date = datetime.now().date()
        days_to_current_date = (current_date - last_date.date()).days
        total_days_ahead = days_to_current_date + days_ahead

        forecast_index = pd.date_range(start=ts.index[-1], periods=total_days_ahead+1, freq='D')[1:]
        
        forecast = sarima_model.get_forecast(steps=len(forecast_index))
        predicted_closes = forecast.predicted_mean.values

        target_dates = [forecast_index[i].strftime('%Y-%m-%d') for i in range(len(forecast_index))]
        predictions = {target_dates[i]: predicted_closes[i] for i in range(len(forecast_index))}

        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices using SARIMA model: {str(e)}")
        return None

# Load SARIMA models on application startup
sarima_models = load_sarima_models()

@app.route('/predict/next_month_sarima', methods=['POST'])
def predict_next_month_sarima():
    ticker = request.json['ticker']
    
    try:
        if ticker not in sarima_models:
            return jsonify({'error': f'Model for {ticker} not found.'}), 404
        
        historical_data = fetch_historical_data(ticker)
        if historical_data is None:
            return jsonify({'error': f'Failed to fetch historical data for {ticker}.'}), 500
        
        sarima_model = sarima_models[ticker]
        predictions = predict_stock_prices_sarima(sarima_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            current_date = datetime.now().date().strftime('%Y-%m-%d')
            predictions = {date: value for date, value in predictions.items() if date >= current_date}
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices using SARIMA model.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if _name_ == '_main_':
    app.run(debug=True)

SARIMAX MODEL
train.py
import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
import pickle
import os
import warnings
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore")

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    
    df['Open_lag'] = df['Open'].shift(1)
    df['Close_lag'] = df['Close'].shift(1)
    df.dropna(inplace=True)
    
    return df[['Adj Close', 'Open_lag', 'Close_lag']]

def train_sarimax_model(ticker, df, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):
    try:
        model = SARIMAX(df['Adj Close'], exog=df[['Open_lag', 'Close_lag']], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)
        fitted_model = model.fit(disp=False)
        os.makedirs('models', exist_ok=True)
        with open(f'models/{ticker}_sarimax_model.pkl', 'wb') as f:
            pickle.dump(fitted_model, f)
        print(f"SARIMAX model trained and saved successfully for {ticker}.")
    except Exception as e:
        print(f"Error training SARIMAX model for {ticker}: {str(e)}")

if _name_ == '_main_':
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_sarimax_model(ticker, ts)

app.py
from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.statespace.sarimax import SARIMAX

app = Flask(_name_)

# Function to load SARIMAX models from pickle files
def load_sarimax_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'F', 'CAT', 'TCS.NS', 'WFC', 'TATASTEEL.NS', 'NFLX', 'RS', 'JPM', 'TSLA']
    models = {}
    for ticker in tickers:
        try:
            with open(f'models/{ticker}_sarimax_model.pkl', 'rb') as f:
                model = pickle.load(f)
                models[ticker] = model
                print(f"Loaded SARIMAX model for {ticker}.")
        except Exception as e:
            print(f"Error loading SARIMAX model for {ticker}: {str(e)}")
    return models

# Function to fetch historical data from MongoDB
def fetch_historical_data(ticker):
    try:
        client = MongoClient('mongodb://localhost:27017/')
        db = client['stockdata']
        collection = db['daily_price']
        cursor = collection.find({'Ticker': ticker})
        df = pd.DataFrame(list(cursor))
        client.close()
        return df
    except Exception as e:
        print(f"Error fetching data from MongoDB for {ticker}: {str(e)}")
        return None

# Function to preprocess data for SARIMAX model prediction
def preprocess_data_for_sarimax(df):
    try:
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        
        df['Open_lag'] = df['Open'].shift(1)
        df['Close_lag'] = df['Close'].shift(1)
        df.dropna(inplace=True)
        
        return df[['Adj Close', 'Open_lag', 'Close_lag']]
    except Exception as e:
        print(f"Error preprocessing data for SARIMAX model: {str(e)}")
        return None

# Function to predict stock prices using a SARIMAX model
def predict_stock_prices_sarimax(sarimax_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_sarimax(latest_data)
        if ts is None:
            return None

        # Number of days to predict to reach the current date and 30 days ahead
        last_date = ts.index[-1]
        current_date = datetime.now().date()
        days_to_current_date = (current_date - last_date.date()).days
        total_days_ahead = days_to_current_date + days_ahead

        forecast_index = pd.date_range(start=ts.index[-1], periods=total_days_ahead+1, freq='D')[1:]
        last_known_open = ts['Open_lag'].iloc[-1]
        last_known_close = ts['Close_lag'].iloc[-1]

        forecast_exog = pd.DataFrame({
            'Open_lag': [last_known_open] * len(forecast_index),
            'Close_lag': [last_known_close] * len(forecast_index)
        }, index=forecast_index)

        forecast = sarimax_model.get_forecast(steps=len(forecast_index), exog=forecast_exog)
        predicted_closes = forecast.predicted_mean.values

        target_dates = [forecast_index[i].strftime('%Y-%m-%d') for i in range(len(forecast_index))]
        predictions = {target_dates[i]: predicted_closes[i] for i in range(len(forecast_index))}

        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices using SARIMAX model: {str(e)}")
        return None

# Load SARIMAX models on application startup
sarimax_models = load_sarimax_models()

@app.route('/predict/next_month', methods=['POST'])
def predict_next_month_sarimax():
    ticker = request.json['ticker']
    
    try:
        if ticker not in sarimax_models:
            return jsonify({'error': f'Model for {ticker} not found.'}), 404
        
        historical_data = fetch_historical_data(ticker)
        if historical_data is None:
            return jsonify({'error': f'Failed to fetch historical data for {ticker}.'}), 500
        
        sarimax_model = sarimax_models[ticker]
        predictions = predict_stock_prices_sarimax(sarimax_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            current_date = datetime.now().date().strftime('%Y-%m-%d')
            predictions = {date: value for date, value in predictions.items() if date >= current_date}
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices using SARIMAX model.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if _name_ == '_main_':
    app.run(debug=True)


I want to split my historical data into train and validation data based on split date and want to compare the accuracy for all these 3 models.
 I want code to predict accuracy alone so give only as python file which displays actual and forecasted values for all models and prints accuracy of each and plot graph
