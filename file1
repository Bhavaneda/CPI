
import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.vector_ar.var_model import VAR
import pickle
import os
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    
    client.close()
    return df

def test_stationarity(timeseries):
    result = adfuller(timeseries)
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')
    for key, value in result[4].items():
        print(f'Critical Value {key}: {value}')
    return result[1] < 0.05

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    df = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]
    
    # Check and make series stationary
    for column in df.columns:
        p_value = test_stationarity(df[column])
        if not p_value:
            df[column] = df[column].diff().dropna()
    
    scaler = StandardScaler()
    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)
    return scaled_df

def check_residuals(var_model):
    residuals = var_model.resid
    fig, axes = plt.subplots(nrows=var_model.neqs, ncols=1, figsize=(10, 10))
    for i in range(var_model.neqs):
        axes[i].plot(residuals[:, i])
        axes[i].set_title(f'Residuals of equation {i+1}')
    plt.tight_layout()
    plt.show()

def check_model_stability(var_model):
    stability = var_model.is_stable()
    print(f'Model Stability: {stability}')
    return stability

def train_var_model(ticker, ts):
    try:
        model = VAR(ts)
        lag_order = model.select_order(maxlags=15)
        best_lag = lag_order.aic
        var_model = model.fit(best_lag)
        
        if not check_model_stability(var_model):
            print(f"Model is not stable for {ticker}.")
            return
        
        check_residuals(var_model)

        os.makedirs('model', exist_ok=True)

        with open(f'model/{ticker}_var_model.pkl', 'wb') as f:
            pickle.dump(var_model, f)
        
        print(f"VAR model trained and saved successfully for {ticker} with lag order {best_lag}.")

    except Exception as e:
        print(f"Error training VAR model for {ticker}: {str(e)}")

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL']
    
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_var_model(ticker, ts)






from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.vector_ar.var_model import VAR

app = Flask(__name__)

def load_var_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL']
    models = {}
    for ticker in tickers:
        with open(f'model/{ticker}_var_model.pkl', 'rb') as f:
            model = pickle.load(f)
            models[ticker] = model
    return models

def fetch_historical_data(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data_for_var(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    df = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]
    
    for column in df.columns:
        df[column] = df[column].diff().dropna()
    
    return df

def predict_stock_prices(var_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_var(latest_data)
        lag_order = var_model.k_ar
        forecast_input = ts.values[-lag_order:]

        forecast = var_model.forecast(forecast_input, steps=days_ahead)
        predicted_closes = forecast[:, 3]

        target_dates = [(datetime.now() + timedelta(days=i)).date() for i in range(1, days_ahead + 1)]
        predictions = {target_dates[i].strftime('%Y-%m-%d'): predicted_closes[i] for i in range(days_ahead)}
        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices: {str(e)}")
        return None

@app.route('/predict/current_day', methods=['POST'])
def predict_current_day():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=1)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'prediction': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock price.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_week', methods=['POST'])
def predict_next_week():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=7)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_month', methods=['POST'])
def predict_next_month():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)









import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.vector_ar.var_model import VAR
import pickle
import os
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    
    client.close()
    return df

def test_stationarity(timeseries):
    result = adfuller(timeseries)
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')
    for key, value in result[4].items():
        print(f'Critical Value {key}: {value}')

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    scaler = StandardScaler()
    scaled_df = pd.DataFrame(scaler.fit_transform(df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]), columns=['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], index=df.index)
    return scaled_df

def check_residuals(var_model):
    residuals = var_model.resid
    fig, axes = plt.subplots(nrows=var_model.neqs, ncols=1, figsize=(10, 10))
    for i in range(var_model.neqs):
        axes[i].plot(residuals[:, i])
        axes[i].set_title(f'Residuals of equation {i+1}')
    plt.tight_layout()
    plt.show()

def check_model_stability(var_model):
    stability = var_model.is_stable()
    print(f'Model Stability: {stability}')

def train_var_model(ticker, ts):
    try:
        model = VAR(ts)
        lag_order = model.select_order(maxlags=15)
        best_lag = lag_order.aic
        var_model = model.fit(best_lag)
        
        check_model_stability(var_model)
        check_residuals(var_model)

        os.makedirs('model', exist_ok=True)

        with open(f'model/{ticker}_var_model.pkl', 'wb') as f:
            pickle.dump(var_model, f)
        
        print(f"VAR model trained and saved successfully for {ticker} with lag order {best_lag}.")

    except Exception as e:
        print(f"Error training VAR model for {ticker}: {str(e)}")

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL']  # Adjust the tickers as needed
    
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_var_model(ticker, ts)





from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.vector_ar.var_model import VAR

app = Flask(__name__)

def load_var_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL']
    models = {}
    for ticker in tickers:
        with open(f'models/{ticker}_var_model.pkl', 'rb') as f:
            model = pickle.load(f)
            models[ticker] = model
    return models

def fetch_historical_data(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data_for_var(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def predict_stock_prices(var_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_var(latest_data)
        lag_order = var_model.k_ar
        forecast_input = ts.values[-lag_order:]

        forecast = var_model.forecast(forecast_input, steps=days_ahead)
        predicted_closes = forecast[:, 3]

        target_dates = [(datetime.now() + timedelta(days=i)).date() for i in range(1, days_ahead + 1)]
        predictions = {target_dates[i].strftime('%Y-%m-%d'): predicted_closes[i] for i in range(days_ahead)}
        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices: {str(e)}")
        return None

@app.route('/predict/current_day', methods=['POST'])
def predict_current_day():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=1)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'prediction': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock price.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_week', methods=['POST'])
def predict_next_week():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=7)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_month', methods=['POST'])
def predict_next_month():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)



import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.vector_ar.var_model import VAR
import pickle
import os

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    
    client.close()
    return df

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    return df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]

def train_var_model(ticker, ts):
    try:
        model = VAR(ts)
        # Select the best lag order based on AIC
        lag_order = model.select_order(maxlags=15)
        best_lag = lag_order.aic
        var_model = model.fit(best_lag)

        os.makedirs('model', exist_ok=True)

        with open(f'model/{ticker}_var_model.pkl', 'wb') as f:
            pickle.dump(var_model, f)
        
        print(f"VAR model trained and saved successfully for {ticker} with lag order {best_lag}.")

    except Exception as e:
        print(f"Error training VAR model for {ticker}: {str(e)}")

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL']  # Adjust the tickers to exclude AMZN for now
    
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_var_model(ticker, ts)



import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.statespace.sarimax import SARIMAX
import pickle
import os

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']  # Adjust collection name as per your MongoDB setup
    
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    
    client.close()
    return df

def preprocess_data(df):
    # Convert 'Date' to datetime format
    df['Date'] = pd.to_datetime(df['Date'])
    
    # Set 'Date' as index
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    
    # Select 'Close' price as the endogenous variable (univariate)
    ts = df['Close']
    
    return ts

def train_sarima_model(ts, ticker):
    try:
        # Train SARIMA model
        model = SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))  # Example SARIMA parameters
        fitted_model = model.fit()

        os.makedirs('models', exist_ok=True)

        with open(f'models/{ticker}_sarima_model.pkl', 'wb') as f:
            pickle.dump(fitted_model, f)
        
        print(f"SARIMA model trained and saved successfully for {ticker}.")

    except Exception as e:
        print(f"Error training SARIMA model for {ticker}: {str(e)}")

def main():
    # List of ticker symbols
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']  # Example tickers
    
    for ticker in tickers:
        # Fetch data from MongoDB
        data = fetch_data_from_mongodb(ticker)
        
        # Preprocess data
        ts = preprocess_data(data)
        
        # Train SARIMA model
        train_sarima_model(ts, ticker)

if __name__ == '__main__':
    main()





import pandas as pd
from pymongo import MongoClient
from statsmodels.tsa.vector_ar.var_model import VAR
import pickle
import os
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller

def fetch_data_from_mongodb(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    
    client.close()
    return df

def test_stationarity(timeseries):
    result = adfuller(timeseries)
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')
    for key, value in result[4].items():
        print(f'Critical Value {key}: {value}')

def preprocess_data(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    scaler = StandardScaler()
    scaled_df = pd.DataFrame(scaler.fit_transform(df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]), columns=['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], index=df.index)
    return scaled_df

def check_residuals(var_model):
    residuals = var_model.resid
    fig, axes = plt.subplots(nrows=var_model.neqs, ncols=1, figsize=(10, 10))
    for i in range(var_model.neqs):
        axes[i].plot(residuals[:, i])
        axes[i].set_title(f'Residuals of equation {i+1}')
    plt.tight_layout()
    plt.show()

def check_model_stability(var_model):
    stability = var_model.is_stable()
    print(f'Model Stability: {stability}')

def train_var_model(ticker, ts):
    try:
        model = VAR(ts)
        lag_order = model.select_order(maxlags=15)
        best_lag = lag_order.aic
        var_model = model.fit(best_lag)
        
        check_model_stability(var_model)
        check_residuals(var_model)

        os.makedirs('model', exist_ok=True)

        with open(f'model/{ticker}_var_model.pkl', 'wb') as f:
            pickle.dump(var_model, f)
        
        print(f"VAR model trained and saved successfully for {ticker} with lag order {best_lag}.")

    except Exception as e:
        print(f"Error training VAR model for {ticker}: {str(e)}")

if __name__ == '__main__':
    tickers = ['AAPL', 'MSFT', 'GOOGL']  # Adjust the tickers as needed
    
    for ticker in tickers:
        data = fetch_data_from_mongodb(ticker)
        ts = preprocess_data(data)
        train_var_model(ticker, ts)






from flask import Flask, request, jsonify
import pandas as pd
import pickle
from pymongo import MongoClient
from datetime import datetime, timedelta
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.preprocessing import StandardScaler
import numpy as np

app = Flask(__name__)

def load_var_models():
    tickers = ['AAPL', 'MSFT', 'GOOGL']
    models = {}
    for ticker in tickers:
        with open(f'model/{ticker}_var_model.pkl', 'rb') as f:
            model = pickle.load(f)
            models[ticker] = model
    return models

def fetch_historical_data(ticker):
    client = MongoClient('mongodb://localhost:27017/')
    db = client['stockdata']
    collection = db['daily_price']
    cursor = collection.find({'Ticker': ticker})
    df = pd.DataFrame(list(cursor))
    client.close()
    return df

def preprocess_data_for_var(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    df.sort_index(inplace=True)
    scaler = StandardScaler()
    scaled_df = pd.DataFrame(scaler.fit_transform(df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]), columns=['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], index=df.index)
    return scaled_df

def predict_stock_prices(var_model, latest_data, days_ahead):
    try:
        ts = preprocess_data_for_var(latest_data)
        lag_order = var_model.k_ar
        forecast_input = ts.values[-lag_order:]

        # Rolling Forecast Example
        forecast = []
        for i in range(days_ahead):
            fc = var_model.forecast(forecast_input, steps=1)
            forecast.append(fc[0])
            forecast_input = np.vstack([forecast_input, fc])
            forecast_input = forecast_input[1:]
        
        forecast = np.array(forecast)
        predicted_closes = forecast[:, 3]

        target_dates = [(datetime.now() + timedelta(days=i)).date() for i in range(1, days_ahead + 1)]
        predictions = {target_dates[i].strftime('%Y-%m-%d'): predicted_closes[i] for i in range(days_ahead)}
        return predictions
    
    except Exception as e:
        print(f"Error predicting stock prices: {str(e)}")
        return None

@app.route('/predict/current_day', methods=['POST'])
def predict_current_day():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=1)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'prediction': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock price.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_week', methods=['POST'])
def predict_next_week():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=7)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/predict/next_month', methods=['POST'])
def predict_next_month():
    ticker = request.json['ticker']
    
    try:
        historical_data = fetch_historical_data(ticker)
        models = load_var_models()
        var_model = models[ticker]
        predictions = predict_stock_prices(var_model, historical_data, days_ahead=30)
        
        if predictions is not None:
            return jsonify({'ticker': ticker, 'predictions': predictions})
        else:
            return jsonify({'error': 'Failed to predict stock prices.'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)



